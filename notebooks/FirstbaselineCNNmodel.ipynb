{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model with pre-trained VGG16 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import models\n",
    "from keras.tensorflow import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "### Load pre-trained model weights of VGG16 from keras\n",
    "def load_model():\n",
    "    model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(100,50,3))\n",
    "    return model\n",
    "\n",
    "### As it is a lot of weights we dont want to re-train them as it would take foreva\n",
    "def set_non_trainable_layers(model):\n",
    "    model.trainable=False\n",
    "    return model\n",
    "\n",
    "### Adding the flatten layer and the dense layers, this are the weeights we will be training\n",
    "def add_last_layers(model):\n",
    "    base_model=set_non_trainable_layers(model)\n",
    "    flattening_layer=layers.Flatten()\n",
    "    dense_layer_1=layers.Dense(64,activation='relu')\n",
    "    dropout_layer=layers.Dropout(0.15)\n",
    "    dense_layer_2=layers.Dense(32,activation='relu')\n",
    "    prediction_layer=layers.Dense(1,activation='sigmoid')\n",
    "\n",
    "    model=models.Sequential([\n",
    "                            base_model,\n",
    "                            flatten__layer,\n",
    "                            dense_layer_1,\n",
    "                            dropout_layer,\n",
    "                            dense_layer_2,\n",
    "                            prediction_layer\n",
    "                            ])\n",
    "    return model\n",
    "\n",
    "### Add the compiler\n",
    "def compile_model(model):\n",
    "\n",
    "    opt = optimizers.Adam(learning_rate=0.1)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "###Actually building the model now using the functions above\n",
    "def build_model():\n",
    "\n",
    "    model = load_model()\n",
    "    model = add_last_layers(model)\n",
    "    model = compile_model(model)\n",
    "\n",
    "    return model\n",
    "\n",
    "#model = build_model() ## uncomment if you want to build the model\n",
    "\n",
    "### Fitting the model\n",
    "def fit_model(model,X_train,y_train):\n",
    "    es=EarlyStopping(patience=7,restore_best_weights=True)\n",
    "\n",
    "    history=model.fit(X_train,y_train,validation_split=0.2,batch_size=16,\n",
    "                    epochs=600,callbacks=[es],verbose=1)\n",
    "    return history\n",
    "\n",
    "### First baseline evaluation\n",
    "def evaluate_model(model,X_test,y_test):\n",
    "    res=model.evaluate(X_test,y_test,verbose=0)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model with ImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping(patience=7,restore_best_weights=True)\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "history=model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=1000,callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First test accuracy forr baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred=model.evaluate_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
